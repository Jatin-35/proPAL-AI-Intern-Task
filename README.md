# ðŸ¤– LiveKit AI Voice Assistant â€“ Internship Task

This project implements a **real-time AI voice assistant** using [LiveKit Agents](https://docs.livekit.io/agents/), combining **STT**, **LLM**, and **TTS** in a seamless pipeline. The assistant supports multilingual speech, logs performance metrics, handles conversation interruptions, and responds with natural-sounding speech.

---

## ðŸš€ Features

- ðŸŽ™ï¸ Real-time **Speech-to-Text (STT)** via Deepgram
- ðŸ§  **LLM inference** via Groq using `llama3-8b-8192`
- ðŸ—£ï¸ High-quality **Text-to-Speech (TTS)** using Cartesia
- ðŸŒ Multilingual voice input support
- ðŸ” **Turn detection** and robust VAD
- ðŸ”‡ Noise cancellation with LiveKit BVC
- ðŸ“Š **Metric logging**: EOU delay, TTFT, TTFB, Total Latency
- ðŸ“„ Exports call performance logs to Excel
- âœ… Supports live & local run modes
- â˜ï¸ LiveKit Cloud support for real-time streaming

---

## ðŸ“ Project Structure

```
AI-VOICE-AGENT/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ agent.py # Main assistant logic
â”‚ â”œâ”€â”€ metrics.py # Excel logging for performance metrics
â”‚ â””â”€â”€ pycache/
â”œâ”€â”€ .env # API keys and credentials
â”œâ”€â”€ .gitignore
â”œâ”€â”€ metrics.xlxs # contains log details
â”œâ”€â”€ requirements.txt # Project dependencies

```

---

## âš™ï¸ Requirements

- Python 3.10+
- Virtual environment (`venv` recommended)
- [LiveKit SDK for Python](https://docs.livekit.io)
- API Keys:
  - Deepgram (STT)
  - Groq (LLM)
  - ElevenLabs or Cartesia (TTS)
  - LiveKit Cloud (RTC + Agent)

---

## ðŸš€ Getting Started

### 1. Clone the Repository

```bash
  - git clone https://github.com/yourusername/ai-voice-assistant.git
  - cd ai-voice-assistant
```

### 2. Setup Virtual Environment
```
 - python -m venv venv

  # On Unix/macOS
  - source venv/bin/activate

  # On Windows
  -venv\Scripts\activate

```

### 3. Install Dependencies

```
  - pip install "livekit-agents[deepgram,groq,elevenlabs,openai ,cartesia,silero,turn-detector]~=1.0" "livekit-plugins-noise-cancellation~=0.2" python-dotenv openpyxl

```

### 4. Then Run this

```
  # To save current installed packages to a file:
  - pip freeze > requirements.txt

```

### 4. Configure .env
Create a .env file in the root directory with your credentials:

```
  - LIVEKIT_URL=wss://your-project.livekit.cloud
  - LIVEKIT_API_KEY=your_livekit_api_key
  - LIVEKIT_API_SECRET=your_livekit_api_secret

  - DEEPGRAM_API_KEY=your_deepgram_api_key
  - CARTESIA_API_KEY=your_cartesia_api_key
  - GROQ_API_KEY=your_groq_api_key
  - ELEVENLABS_API_KEY=your_elevenlabs_api_key

```

## â–¶ï¸ Run the Assistant
### ðŸ–¥ï¸ Run Locally (Console Mode)

```
  # This runs the assistant locally for development or testing purposes using console mode.
  - python src/agent.py console

```

### â˜ï¸ Run on LiveKit Cloud (Playground)

```
  # This runs the assistant on LiveKit Cloud using the LiveKit Agents Playground.
  - python src/agent.py dev


```

--> âš ï¸ Note: Ensure your .env file is configured correctly with valid API keys and URLs before launching.

---

## ðŸ“Š Metrics Logging
- The metrics.py file collects and logs important real-time performance statistics:

- EOU Delay â€“ Time taken to detect the end of the user's utterance.

- TTFT (Time To First Token) â€“ Time taken by the LLM to generate the first token.

- TTFB (Time To First Byte) â€“ Time taken by the TTS engine to begin audio output.

- Total Latency â€“ Combined system response time from input to voice reply.

ðŸ“ Metrics are saved as Excel sheets in the local directory for later evaluation.

--- 
## ðŸ§ª Example Prompt

The assistant automatically greets the user on joining:
```
  --> "Hello! How can I assist you today?"
```

---
## ðŸ™Œ Acknowledgements
  - LiveKit
  - Groq
  - Deepgram
  - Cartesia
  - ElevenLabs


